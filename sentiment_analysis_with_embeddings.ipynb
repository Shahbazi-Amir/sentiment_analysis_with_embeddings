{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd41bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: gensim in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/macbookpro/Library/Python/3.11/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/macbookpro/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install neccery libs\n",
    "!pip install pandas numpy scikit-learn nltk gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593f4ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fec0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/macbookpro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "955dbe41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# نمایش چند کلمه stopword\n",
    "print(stopwords.words('english')[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a310e33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ تعداد داده‌ها: 1048572\n",
      "توزیع کلاس‌ها:\n",
      "sentiment\n",
      "0    799996\n",
      "4    248576\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# خواندن دیتاست با ستون‌های مناسب\n",
    "file_path = 'training.1600000.processed.noemoticon.csv'\n",
    "column_names = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n",
    "\n",
    "df = pd.read_csv(\n",
    "    file_path,\n",
    "    header=0,  # سطر اول header هست\n",
    "    encoding='latin1',\n",
    "    names=column_names,\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# فیلتر فقط برای 0 و 4\n",
    "df = df[df['sentiment'].isin([0, 4])]\n",
    "\n",
    "print(\"✅ تعداد داده‌ها:\", len(df))\n",
    "print(\"توزیع کلاس‌ها:\")\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99451f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# تنظیم stop words + کلمات اضافی\n",
    "stop_words = set(stopwords.words('english'))\n",
    "extra_stopwords = {'rt', 'user', 'url', '…', 'amp', 'via', 'http', 'https'}\n",
    "all_stopwords = stop_words.union(extra_stopwords)\n",
    "\n",
    "# تابع پیش‌پردازش بهتر شده\n",
    "def preprocess_text_improved(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'@\\S+', '', text)\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    text = re.sub(r'#\\S+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    tokens = text.split()\n",
    "    filtered_tokens = [word for word in tokens if word not in all_stopwords]\n",
    "    return filtered_tokens\n",
    "\n",
    "# اعمال پیش‌پردازش\n",
    "df['tokens'] = df['text'].apply(preprocess_text_improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca685ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ مدل embedding با موفقیت دانلود و بارگذاری شد!\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# دانلود مدل \"glove-twitter-25\" - حدود 86 مگابایت\n",
    "embedding_model = api.load(\"glove-twitter-25\")\n",
    "\n",
    "print(\"✅ مدل embedding با موفقیت دانلود و بارگذاری شد!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83d51b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ابعاد X: (1048572, 25)\n",
      "✅ ابعاد y: (1048572,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# تابع برای تبدیل tokens به بردار (با استفاده از GloVe)\n",
    "def text_to_vector(tokens, model, vector_size=25):\n",
    "    vectors = [model[word] for word in tokens if word in model]\n",
    "    if not vectors:\n",
    "        return np.zeros(vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# اعمال تابع برای تمام داده‌ها\n",
    "X = np.array(df['tokens'].apply(text_to_vector, model=embedding_model).tolist())\n",
    "y = df['sentiment'].map({0: 0, 4: 1})  # 0 = منفی، 1 = مثبت\n",
    "\n",
    "print(\"✅ ابعاد X:\", X.shape)\n",
    "print(\"✅ ابعاد y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25065bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ X_train shape: (838857, 25)\n",
      "✅ X_test shape: (209715, 25)\n",
      "✅ y_train shape: (838857,)\n",
      "✅ y_test shape: (209715,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# تقسیم داده به train و test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2,     # 80% train, 20% test\n",
    "    random_state=42,   # ثابت کردن رندوم برای قابلیت تکرار\n",
    "    stratify=y         # حفظ توزیع کلاس‌ها در train و test\n",
    ")\n",
    "\n",
    "# چاپ ابعاد\n",
    "print(\"✅ X_train shape:\", X_train.shape)\n",
    "print(\"✅ X_test shape:\", X_test.shape)\n",
    "print(\"✅ y_train shape:\", y_train.shape)\n",
    "print(\"✅ y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfceccba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 دقت مدل: 0.7856\n",
      "\n",
      "📋 گزارش طبقه‌بندی:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.87    160000\n",
      "           1       0.65      0.20      0.31     49715\n",
      "\n",
      "    accuracy                           0.79    209715\n",
      "   macro avg       0.72      0.59      0.59    209715\n",
      "weighted avg       0.76      0.79      0.74    209715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# ساخت و آموزش مدل\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# پیش‌بینی روی test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# محاسبه دقت و گزارش طبقه‌بندی\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"🎯 دقت مدل: {accuracy:.4f}\")\n",
    "print(\"\\n📋 گزارش طبقه‌بندی:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00510315",
   "metadata": {},
   "source": [
    "<div style = \"direction : rtl;\">\n",
    "\n",
    "\n",
    "عالی! 🙌  \n",
    "خب، فهمیدم که **`precision`, `recall`, و `f1-score` رو هنوز کامل نفهمیدی** – ولی نگران نباش، الان یه توضیح ساده و با مثال بهت میدم که دیگه هرگز فراموش نکنی 😎\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 اول بفهمیم چرا accuracy کافی نیست؟\n",
    "\n",
    "### 💡 مثال: ۱۰۰۰ نظر داریم:\n",
    "| کلاس | تعداد |\n",
    "|------|--------|\n",
    "| منفی (`0`) | 950 |\n",
    "| مثبت (`1`) | 50 |\n",
    "\n",
    "فرض کن مدل همه‌شون رو منفی پیش‌بینی کنه (حتی بدون دیدن داده!)  \n",
    "اینطوری:\n",
    "\n",
    "- فقط 950 تا درست شناخته شده\n",
    "- 50 تا اشتباه (همه مثبت‌ها رو منفی گرفته)\n",
    "\n",
    "### ✅ دقت accuracy چقدر میشه؟\n",
    "\n",
    "```\n",
    "Accuracy = تعداد پیش‌بینی‌های درست / کل داده‌ها\n",
    "       = 950 / 1000\n",
    "       = 0.95 → 95%\n",
    "```\n",
    "\n",
    "😱 یعنی دقت خیلی خوبه، ولی مدل **هیچ مثبتی رو تشخیص نداده!**\n",
    "\n",
    "پس **دقت (accuracy) گمراه‌کننده است وقتی داده‌ها نابرابرند.**\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 معیارهای جدید: Precision, Recall, F1-score\n",
    "\n",
    "### ⚖️ این سه معیار توی طبقه‌بندی بسیار مهم‌تر هستن.\n",
    "\n",
    "فرض کنیم مدل ما یه **دکتر** هست و داره روی نظرات **سرطان تشخیص بده**!\n",
    "\n",
    "| کلمه‌ها | معادل ساده |\n",
    "|---------|-------------|\n",
    "| `Precision` | از بین تمام بیمارانی که گفت \"سرطان دارن\"، چند درصد واقعاً سرطان داشتن؟ |\n",
    "| `Recall` | از بین تمام بیماران واقعی که سرطان داشتن، چند درصد رو مدل تشخیص داد؟ |\n",
    "| `F1-Score` | میانگین هارمونیک precision و recall – وقتی دو تا عدد نسبتاً متوسط داشته باشیم، بالا میشه |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 تعریف دقیق‌تر با مثال:\n",
    "\n",
    "### فرض کنیم 100 نظر مثبت وجود داره (واقعی) و مدل 200 تا رو **پیش‌بینی مثبت** کرده:\n",
    "\n",
    "| نوع | تعداد |\n",
    "|-----|--------|\n",
    "| `True Positive (TP)` | 40 نفر (واقعاً مثبت بود + مدل درست تشخیص داد) |\n",
    "| `False Positive (FP)` | 160 نفر (منفی بود + مدل اشتباه گفت مثبت) |\n",
    "| `False Negative (FN)` | 60 نفر (مثبت بود + مدل گفت منفی) |\n",
    "| `True Negative (TN)` | نمی‌خوایم الان راجبش حرف بزنیم |\n",
    "\n",
    "### ✅ محاسبه:\n",
    "\n",
    "- `precision = TP / (TP + FP) = 40 / (40+160) = 0.20`\n",
    "- `recall = TP / (TP + FN) = 40 / (40+60) = 0.40`\n",
    "\n",
    "> یعنی:\n",
    "- فقط 20٪ از جمله‌هایی که مدل گفت مثبت هستند، واقعاً مثبت بودند.\n",
    "- فقط 40٪ از جمله‌های واقعاً مثبت رو مدل تشخیص داد.\n",
    "\n",
    "---\n",
    "\n",
    "## 📉 حالا برویم سراغ خروجی تو:\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.97      0.87    160000\n",
    "           1       0.65      0.20      0.31     49715\n",
    "```\n",
    "\n",
    "### 🔍 برای کلاس `0` (منفی):\n",
    "\n",
    "- `precision = 0.80`: از بین تمام جمله‌هایی که مدل گفت منفی هستند، 80٪ واقعاً منفی بودند.\n",
    "- `recall = 0.97`: از بین تمام جمله‌های واقعاً منفی، 97٪ رو مدل تشخیص داده.\n",
    "- `f1-score = 0.87`: تعادل خوبی بین precision و recall\n",
    "\n",
    "✅ یعنی مدل **خیلی خوب توی تشخیص جمله منفی**\n",
    "\n",
    "---\n",
    "\n",
    "### 🔻 برای کلاس `1` (مثبت):\n",
    "\n",
    "- `precision = 0.65`: از بین تمام جمله‌هایی که مدل گفت مثبت هستند، 65٪ واقعاً مثبت بودند.\n",
    "- `recall = 0.20`: فقط 20٪ از تمام جمله‌های واقعاً مثبت رو تشخیص داده!\n",
    "- `f1-score = 0.31`: خیلی بد – یعنی هم precision و هم recall ضعیف هستن\n",
    "\n",
    "🔴 یعنی مدل **خیلی بد توی تشخیص جمله مثبت عمل کرده**\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 تفاوت این معیارها با `accuracy` چیه؟\n",
    "\n",
    "| معیار | فرمول | چه زمانی مهمه؟ |\n",
    "|-------|--------|----------------|\n",
    "| `accuracy` | `(TP + TN) / (TP + TN + FP + FN)` | وقتی داده‌ها متوازن هستن |\n",
    "| `precision` | `TP / (TP + FP)` | وقتی **تصادفات کاذب (false positives)** مهمه (مثل تشخیص اسپم) |\n",
    "| `recall` | `TP / (TP + FN)` | وقتی **جمله‌های واقعاً مثبت رو نباید از دست بدیم** (مثل تشخیص بیماری) |\n",
    "| `F1-score` | `2 * (P * R) / (P + R)` | وقتی **هر دو precision و recall مهمه**\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 تحلیل دقت توی خروجی تو:\n",
    "\n",
    "```\n",
    "🎯 دقت مدل: 0.7856\n",
    "```\n",
    "\n",
    "این عدد یعنی:\n",
    "- مدل روی 78.56٪ از کل داده‌ها درست پیش‌بینی کرده\n",
    "\n",
    "اما چون داده‌ها نابرابرند (فقط 49,715 مثبت داریم در برابر 160,000 منفی)، دقت **در واقع گمراه‌کننده هست**.\n",
    "\n",
    "چون مدل بیشتر داده منفی دیده، بیشتر جمله‌ها رو منفی پیش‌بینی میکنه – حتی اگه واقعاً مثبت باشن.\n",
    "\n",
    "---\n",
    "\n",
    "## 🤔 چطور این مشکل رو حل کنیم؟\n",
    "\n",
    "### ✅ راه‌حل ۱: استفاده از `class_weight='balanced'` در مدل\n",
    "\n",
    "```python\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "```\n",
    "\n",
    "این کار باعث میشه مدل **به کلاس مثبت هم وزن بیشتری بده**\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ راه‌حل ۲: استفاده از **resampling** (مثل SMOTE)\n",
    "\n",
    "برای افزایش داده‌های مثبت قبل از آموزش مدل – ولی الان فعلاً اینو فراموش کن\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 خلاصه ساده:\n",
    "\n",
    "| معیار | چی رو اندازه می‌گیره؟ | وقتی مهمه؟ |\n",
    "|-------|----------------------|-------------|\n",
    "| `accuracy` | چند درصد کل پیش‌بینی‌ها درست بود؟ | داده متوازن باشه |\n",
    "| `precision` | وقتی گفت \"مثبت\"، چند درصد درست بود؟ | نخوایم اشتباه بگیم \"مثبت\" (مثل تشخیص ایمیل اسپم) |\n",
    "| `recall` | از بین واقعاً مثبت‌ها، چند درصد رو تشخیص دادیم؟ | نخوایم جمله مثبتی رو از دست بدیم (مثل تشخیص بیماری) |\n",
    "| `f1-score` | تعادل بین precision و recall | هر دو معیار مهم باشن |\n",
    "\n",
    "---\n",
    "\n",
    "## 👇 مرحله بعد:\n",
    "\n",
    "حالا که متوجه شدی این معیارها چی‌کار میکنن، می‌تونیم:\n",
    "\n",
    "1. مدل رو بهتر کنیم (با `class_weight='balanced'`)\n",
    "2. Confusion Matrix رو رسم کنیم\n",
    "3. Cross Validation انجام بدیم\n",
    "4. یا حتی یه شبکه عصبی ساده بنا کنیم\n",
    "\n",
    "---\n",
    "\n",
    "## 🤔 سوال آخر:\n",
    "\n",
    "- الان معیارها رو فهمیدی؟\n",
    "- می‌خوایم چه مرحله‌ای رو ادامه بدیم؟\n",
    "  - الف) بهتر کردن مدل (balance class)\n",
    "  - ب) رسم Confusion Matrix\n",
    "  - ج) Cross Validation\n",
    "  - د) مقایسه با شبکه عصبی\n",
    "\n",
    "منتظر جوابت هستم 😊  \n",
    "وقتی گفتی \"الف\" یا \"ب\" یا ...، من کد و توضیحشو برات می‌فرستم.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586311c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7f49ee5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

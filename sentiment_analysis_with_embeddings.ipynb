{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd41bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: gensim in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (4.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/macbookpro/Library/Python/3.11/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/macbookpro/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install neccery libs\n",
    "!pip install pandas numpy scikit-learn nltk gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593f4ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fec0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/macbookpro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "955dbe41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Ù†Ù…Ø§ÛŒØ´ Ú†Ù†Ø¯ Ú©Ù„Ù…Ù‡ stopword\n",
    "print(stopwords.words('english')[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a310e33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: 1048572\n",
      "ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§:\n",
      "sentiment\n",
      "0    799996\n",
      "4    248576\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯ÛŒØªØ§Ø³Øª Ø¨Ø§ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨\n",
    "file_path = 'training.1600000.processed.noemoticon.csv'\n",
    "column_names = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n",
    "\n",
    "df = pd.read_csv(\n",
    "    file_path,\n",
    "    header=0,  # Ø³Ø·Ø± Ø§ÙˆÙ„ header Ù‡Ø³Øª\n",
    "    encoding='latin1',\n",
    "    names=column_names,\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# ÙÛŒÙ„ØªØ± ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ 0 Ùˆ 4\n",
    "df = df[df['sentiment'].isin([0, 4])]\n",
    "\n",
    "print(\"âœ… ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:\", len(df))\n",
    "print(\"ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§:\")\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99451f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# ØªÙ†Ø¸ÛŒÙ… stop words + Ú©Ù„Ù…Ø§Øª Ø§Ø¶Ø§ÙÛŒ\n",
    "stop_words = set(stopwords.words('english'))\n",
    "extra_stopwords = {'rt', 'user', 'url', 'â€¦', 'amp', 'via', 'http', 'https'}\n",
    "all_stopwords = stop_words.union(extra_stopwords)\n",
    "\n",
    "# ØªØ§Ø¨Ø¹ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù‡ØªØ± Ø´Ø¯Ù‡\n",
    "def preprocess_text_improved(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'@\\S+', '', text)\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    text = re.sub(r'#\\S+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    tokens = text.split()\n",
    "    filtered_tokens = [word for word in tokens if word not in all_stopwords]\n",
    "    return filtered_tokens\n",
    "\n",
    "# Ø§Ø¹Ù…Ø§Ù„ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´\n",
    "df['tokens'] = df['text'].apply(preprocess_text_improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca685ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ù…Ø¯Ù„ embedding Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯!\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ \"glove-twitter-25\" - Ø­Ø¯ÙˆØ¯ 86 Ù…Ú¯Ø§Ø¨Ø§ÛŒØª\n",
    "embedding_model = api.load(\"glove-twitter-25\")\n",
    "\n",
    "print(\"âœ… Ù…Ø¯Ù„ embedding Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83d51b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ø§Ø¨Ø¹Ø§Ø¯ X: (1048572, 25)\n",
      "âœ… Ø§Ø¨Ø¹Ø§Ø¯ y: (1048572,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ tokens Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø± (Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² GloVe)\n",
    "def text_to_vector(tokens, model, vector_size=25):\n",
    "    vectors = [model[word] for word in tokens if word in model]\n",
    "    if not vectors:\n",
    "        return np.zeros(vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# Ø§Ø¹Ù…Ø§Ù„ ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
    "X = np.array(df['tokens'].apply(text_to_vector, model=embedding_model).tolist())\n",
    "y = df['sentiment'].map({0: 0, 4: 1})  # 0 = Ù…Ù†ÙÛŒØŒ 1 = Ù…Ø«Ø¨Øª\n",
    "\n",
    "print(\"âœ… Ø§Ø¨Ø¹Ø§Ø¯ X:\", X.shape)\n",
    "print(\"âœ… Ø§Ø¨Ø¹Ø§Ø¯ y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25065bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… X_train shape: (838857, 25)\n",
      "âœ… X_test shape: (209715, 25)\n",
      "âœ… y_train shape: (838857,)\n",
      "âœ… y_test shape: (209715,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ train Ùˆ test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2,     # 80% train, 20% test\n",
    "    random_state=42,   # Ø«Ø§Ø¨Øª Ú©Ø±Ø¯Ù† Ø±Ù†Ø¯ÙˆÙ… Ø¨Ø±Ø§ÛŒ Ù‚Ø§Ø¨Ù„ÛŒØª ØªÚ©Ø±Ø§Ø±\n",
    "    stratify=y         # Ø­ÙØ¸ ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ Ø¯Ø± train Ùˆ test\n",
    ")\n",
    "\n",
    "# Ú†Ø§Ù¾ Ø§Ø¨Ø¹Ø§Ø¯\n",
    "print(\"âœ… X_train shape:\", X_train.shape)\n",
    "print(\"âœ… X_test shape:\", X_test.shape)\n",
    "print(\"âœ… y_train shape:\", y_train.shape)\n",
    "print(\"âœ… y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfceccba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Ø¯Ù‚Øª Ù…Ø¯Ù„: 0.7856\n",
      "\n",
      "ğŸ“‹ Ú¯Ø²Ø§Ø±Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.87    160000\n",
      "           1       0.65      0.20      0.31     49715\n",
      "\n",
      "    accuracy                           0.79    209715\n",
      "   macro avg       0.72      0.59      0.59    209715\n",
      "weighted avg       0.76      0.79      0.74    209715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Ø³Ø§Ø®Øª Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ù‚Øª Ùˆ Ú¯Ø²Ø§Ø±Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"ğŸ¯ Ø¯Ù‚Øª Ù…Ø¯Ù„: {accuracy:.4f}\")\n",
    "print(\"\\nğŸ“‹ Ú¯Ø²Ø§Ø±Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00510315",
   "metadata": {},
   "source": [
    "<div style = \"direction : rtl;\">\n",
    "\n",
    "\n",
    "Ø¹Ø§Ù„ÛŒ! ğŸ™Œ  \n",
    "Ø®Ø¨ØŒ ÙÙ‡Ù…ÛŒØ¯Ù… Ú©Ù‡ **`precision`, `recall`, Ùˆ `f1-score` Ø±Ùˆ Ù‡Ù†ÙˆØ² Ú©Ø§Ù…Ù„ Ù†ÙÙ‡Ù…ÛŒØ¯ÛŒ** â€“ ÙˆÙ„ÛŒ Ù†Ú¯Ø±Ø§Ù† Ù†Ø¨Ø§Ø´ØŒ Ø§Ù„Ø§Ù† ÛŒÙ‡ ØªÙˆØ¶ÛŒØ­ Ø³Ø§Ø¯Ù‡ Ùˆ Ø¨Ø§ Ù…Ø«Ø§Ù„ Ø¨Ù‡Øª Ù…ÛŒØ¯Ù… Ú©Ù‡ Ø¯ÛŒÚ¯Ù‡ Ù‡Ø±Ú¯Ø² ÙØ±Ø§Ù…ÙˆØ´ Ù†Ú©Ù†ÛŒ ğŸ˜\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Ø§ÙˆÙ„ Ø¨ÙÙ‡Ù…ÛŒÙ… Ú†Ø±Ø§ accuracy Ú©Ø§ÙÛŒ Ù†ÛŒØ³ØªØŸ\n",
    "\n",
    "### ğŸ’¡ Ù…Ø«Ø§Ù„: Û±Û°Û°Û° Ù†Ø¸Ø± Ø¯Ø§Ø±ÛŒÙ…:\n",
    "| Ú©Ù„Ø§Ø³ | ØªØ¹Ø¯Ø§Ø¯ |\n",
    "|------|--------|\n",
    "| Ù…Ù†ÙÛŒ (`0`) | 950 |\n",
    "| Ù…Ø«Ø¨Øª (`1`) | 50 |\n",
    "\n",
    "ÙØ±Ø¶ Ú©Ù† Ù…Ø¯Ù„ Ù‡Ù…Ù‡â€ŒØ´ÙˆÙ† Ø±Ùˆ Ù…Ù†ÙÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ù†Ù‡ (Ø­ØªÛŒ Ø¨Ø¯ÙˆÙ† Ø¯ÛŒØ¯Ù† Ø¯Ø§Ø¯Ù‡!)  \n",
    "Ø§ÛŒÙ†Ø·ÙˆØ±ÛŒ:\n",
    "\n",
    "- ÙÙ‚Ø· 950 ØªØ§ Ø¯Ø±Ø³Øª Ø´Ù†Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡\n",
    "- 50 ØªØ§ Ø§Ø´ØªØ¨Ø§Ù‡ (Ù‡Ù…Ù‡ Ù…Ø«Ø¨Øªâ€ŒÙ‡Ø§ Ø±Ùˆ Ù…Ù†ÙÛŒ Ú¯Ø±ÙØªÙ‡)\n",
    "\n",
    "### âœ… Ø¯Ù‚Øª accuracy Ú†Ù‚Ø¯Ø± Ù…ÛŒØ´Ù‡ØŸ\n",
    "\n",
    "```\n",
    "Accuracy = ØªØ¹Ø¯Ø§Ø¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø³Øª / Ú©Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
    "       = 950 / 1000\n",
    "       = 0.95 â†’ 95%\n",
    "```\n",
    "\n",
    "ğŸ˜± ÛŒØ¹Ù†ÛŒ Ø¯Ù‚Øª Ø®ÛŒÙ„ÛŒ Ø®ÙˆØ¨Ù‡ØŒ ÙˆÙ„ÛŒ Ù…Ø¯Ù„ **Ù‡ÛŒÚ† Ù…Ø«Ø¨ØªÛŒ Ø±Ùˆ ØªØ´Ø®ÛŒØµ Ù†Ø¯Ø§Ø¯Ù‡!**\n",
    "\n",
    "Ù¾Ø³ **Ø¯Ù‚Øª (accuracy) Ú¯Ù…Ø±Ø§Ù‡â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø§Ø³Øª ÙˆÙ‚ØªÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù†Ø§Ø¨Ø±Ø§Ø¨Ø±Ù†Ø¯.**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯: Precision, Recall, F1-score\n",
    "\n",
    "### âš–ï¸ Ø§ÛŒÙ† Ø³Ù‡ Ù…Ø¹ÛŒØ§Ø± ØªÙˆÛŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø³ÛŒØ§Ø± Ù…Ù‡Ù…â€ŒØªØ± Ù‡Ø³ØªÙ†.\n",
    "\n",
    "ÙØ±Ø¶ Ú©Ù†ÛŒÙ… Ù…Ø¯Ù„ Ù…Ø§ ÛŒÙ‡ **Ø¯Ú©ØªØ±** Ù‡Ø³Øª Ùˆ Ø¯Ø§Ø±Ù‡ Ø±ÙˆÛŒ Ù†Ø¸Ø±Ø§Øª **Ø³Ø±Ø·Ø§Ù† ØªØ´Ø®ÛŒØµ Ø¨Ø¯Ù‡**!\n",
    "\n",
    "| Ú©Ù„Ù…Ù‡â€ŒÙ‡Ø§ | Ù…Ø¹Ø§Ø¯Ù„ Ø³Ø§Ø¯Ù‡ |\n",
    "|---------|-------------|\n",
    "| `Precision` | Ø§Ø² Ø¨ÛŒÙ† ØªÙ…Ø§Ù… Ø¨ÛŒÙ…Ø§Ø±Ø§Ù†ÛŒ Ú©Ù‡ Ú¯ÙØª \"Ø³Ø±Ø·Ø§Ù† Ø¯Ø§Ø±Ù†\"ØŒ Ú†Ù†Ø¯ Ø¯Ø±ØµØ¯ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ø³Ø±Ø·Ø§Ù† Ø¯Ø§Ø´ØªÙ†ØŸ |\n",
    "| `Recall` | Ø§Ø² Ø¨ÛŒÙ† ØªÙ…Ø§Ù… Ø¨ÛŒÙ…Ø§Ø±Ø§Ù† ÙˆØ§Ù‚Ø¹ÛŒ Ú©Ù‡ Ø³Ø±Ø·Ø§Ù† Ø¯Ø§Ø´ØªÙ†ØŒ Ú†Ù†Ø¯ Ø¯Ø±ØµØ¯ Ø±Ùˆ Ù…Ø¯Ù„ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯ØŸ |\n",
    "| `F1-Score` | Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡Ø§Ø±Ù…ÙˆÙ†ÛŒÚ© precision Ùˆ recall â€“ ÙˆÙ‚ØªÛŒ Ø¯Ùˆ ØªØ§ Ø¹Ø¯Ø¯ Ù†Ø³Ø¨ØªØ§Ù‹ Ù…ØªÙˆØ³Ø· Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒÙ…ØŒ Ø¨Ø§Ù„Ø§ Ù…ÛŒØ´Ù‡ |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§ª ØªØ¹Ø±ÛŒÙ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ø¨Ø§ Ù…Ø«Ø§Ù„:\n",
    "\n",
    "### ÙØ±Ø¶ Ú©Ù†ÛŒÙ… 100 Ù†Ø¸Ø± Ù…Ø«Ø¨Øª ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù‡ (ÙˆØ§Ù‚Ø¹ÛŒ) Ùˆ Ù…Ø¯Ù„ 200 ØªØ§ Ø±Ùˆ **Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø«Ø¨Øª** Ú©Ø±Ø¯Ù‡:\n",
    "\n",
    "| Ù†ÙˆØ¹ | ØªØ¹Ø¯Ø§Ø¯ |\n",
    "|-----|--------|\n",
    "| `True Positive (TP)` | 40 Ù†ÙØ± (ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù…Ø«Ø¨Øª Ø¨ÙˆØ¯ + Ù…Ø¯Ù„ Ø¯Ø±Ø³Øª ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯) |\n",
    "| `False Positive (FP)` | 160 Ù†ÙØ± (Ù…Ù†ÙÛŒ Ø¨ÙˆØ¯ + Ù…Ø¯Ù„ Ø§Ø´ØªØ¨Ø§Ù‡ Ú¯ÙØª Ù…Ø«Ø¨Øª) |\n",
    "| `False Negative (FN)` | 60 Ù†ÙØ± (Ù…Ø«Ø¨Øª Ø¨ÙˆØ¯ + Ù…Ø¯Ù„ Ú¯ÙØª Ù…Ù†ÙÛŒ) |\n",
    "| `True Negative (TN)` | Ù†Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒÙ… Ø§Ù„Ø§Ù† Ø±Ø§Ø¬Ø¨Ø´ Ø­Ø±Ù Ø¨Ø²Ù†ÛŒÙ… |\n",
    "\n",
    "### âœ… Ù…Ø­Ø§Ø³Ø¨Ù‡:\n",
    "\n",
    "- `precision = TP / (TP + FP) = 40 / (40+160) = 0.20`\n",
    "- `recall = TP / (TP + FN) = 40 / (40+60) = 0.40`\n",
    "\n",
    "> ÛŒØ¹Ù†ÛŒ:\n",
    "- ÙÙ‚Ø· 20Ùª Ø§Ø² Ø¬Ù…Ù„Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ø¯Ù„ Ú¯ÙØª Ù…Ø«Ø¨Øª Ù‡Ø³ØªÙ†Ø¯ØŒ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù…Ø«Ø¨Øª Ø¨ÙˆØ¯Ù†Ø¯.\n",
    "- ÙÙ‚Ø· 40Ùª Ø§Ø² Ø¬Ù…Ù„Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù…Ø«Ø¨Øª Ø±Ùˆ Ù…Ø¯Ù„ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‰ Ø­Ø§Ù„Ø§ Ø¨Ø±ÙˆÛŒÙ… Ø³Ø±Ø§Øº Ø®Ø±ÙˆØ¬ÛŒ ØªÙˆ:\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.97      0.87    160000\n",
    "           1       0.65      0.20      0.31     49715\n",
    "```\n",
    "\n",
    "### ğŸ” Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø§Ø³ `0` (Ù…Ù†ÙÛŒ):\n",
    "\n",
    "- `precision = 0.80`: Ø§Ø² Ø¨ÛŒÙ† ØªÙ…Ø§Ù… Ø¬Ù…Ù„Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ø¯Ù„ Ú¯ÙØª Ù…Ù†ÙÛŒ Ù‡Ø³ØªÙ†Ø¯ØŒ 80Ùª ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù…Ù†ÙÛŒ Ø¨ÙˆØ¯Ù†Ø¯.\n",
    "- `recall = 0.97`: Ø§Ø² Ø¨ÛŒÙ† ØªÙ…Ø§Ù… Ø¬Ù…Ù„Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù…Ù†ÙÛŒØŒ 97Ùª Ø±Ùˆ Ù…Ø¯Ù„ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡.\n",
    "- `f1-score = 0.87`: ØªØ¹Ø§Ø¯Ù„ Ø®ÙˆØ¨ÛŒ Ø¨ÛŒÙ† precision Ùˆ recall\n",
    "\n",
    "âœ… ÛŒØ¹Ù†ÛŒ Ù…Ø¯Ù„ **Ø®ÛŒÙ„ÛŒ Ø®ÙˆØ¨ ØªÙˆÛŒ ØªØ´Ø®ÛŒØµ Ø¬Ù…Ù„Ù‡ Ù…Ù†ÙÛŒ**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”» Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø§Ø³ `1` (Ù…Ø«Ø¨Øª):\n",
    "\n",
    "- `precision = 0.65`: Ø§Ø² Ø¨ÛŒÙ† ØªÙ…Ø§Ù… Ø¬Ù…Ù„Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ø¯Ù„ Ú¯ÙØª Ù…Ø«Ø¨Øª Ù‡Ø³ØªÙ†Ø¯ØŒ 65Ùª ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù…Ø«Ø¨Øª Ø¨ÙˆØ¯Ù†Ø¯.\n",
    "- `recall = 0.20`: ÙÙ‚Ø· 20Ùª Ø§Ø² ØªÙ…Ø§Ù… Ø¬Ù…Ù„Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù…Ø«Ø¨Øª Ø±Ùˆ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡!\n",
    "- `f1-score = 0.31`: Ø®ÛŒÙ„ÛŒ Ø¨Ø¯ â€“ ÛŒØ¹Ù†ÛŒ Ù‡Ù… precision Ùˆ Ù‡Ù… recall Ø¶Ø¹ÛŒÙ Ù‡Ø³ØªÙ†\n",
    "\n",
    "ğŸ”´ ÛŒØ¹Ù†ÛŒ Ù…Ø¯Ù„ **Ø®ÛŒÙ„ÛŒ Ø¨Ø¯ ØªÙˆÛŒ ØªØ´Ø®ÛŒØµ Ø¬Ù…Ù„Ù‡ Ù…Ø«Ø¨Øª Ø¹Ù…Ù„ Ú©Ø±Ø¯Ù‡**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ˆ ØªÙØ§ÙˆØª Ø§ÛŒÙ† Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ Ø¨Ø§ `accuracy` Ú†ÛŒÙ‡ØŸ\n",
    "\n",
    "| Ù…Ø¹ÛŒØ§Ø± | ÙØ±Ù…ÙˆÙ„ | Ú†Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù…Ù‡Ù…Ù‡ØŸ |\n",
    "|-------|--------|----------------|\n",
    "| `accuracy` | `(TP + TN) / (TP + TN + FP + FN)` | ÙˆÙ‚ØªÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù…ØªÙˆØ§Ø²Ù† Ù‡Ø³ØªÙ† |\n",
    "| `precision` | `TP / (TP + FP)` | ÙˆÙ‚ØªÛŒ **ØªØµØ§Ø¯ÙØ§Øª Ú©Ø§Ø°Ø¨ (false positives)** Ù…Ù‡Ù…Ù‡ (Ù…Ø«Ù„ ØªØ´Ø®ÛŒØµ Ø§Ø³Ù¾Ù…) |\n",
    "| `recall` | `TP / (TP + FN)` | ÙˆÙ‚ØªÛŒ **Ø¬Ù…Ù„Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù…Ø«Ø¨Øª Ø±Ùˆ Ù†Ø¨Ø§ÛŒØ¯ Ø§Ø² Ø¯Ø³Øª Ø¨Ø¯ÛŒÙ…** (Ù…Ø«Ù„ ØªØ´Ø®ÛŒØµ Ø¨ÛŒÙ…Ø§Ø±ÛŒ) |\n",
    "| `F1-score` | `2 * (P * R) / (P + R)` | ÙˆÙ‚ØªÛŒ **Ù‡Ø± Ø¯Ùˆ precision Ùˆ recall Ù…Ù‡Ù…Ù‡**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Œ ØªØ­Ù„ÛŒÙ„ Ø¯Ù‚Øª ØªÙˆÛŒ Ø®Ø±ÙˆØ¬ÛŒ ØªÙˆ:\n",
    "\n",
    "```\n",
    "ğŸ¯ Ø¯Ù‚Øª Ù…Ø¯Ù„: 0.7856\n",
    "```\n",
    "\n",
    "Ø§ÛŒÙ† Ø¹Ø¯Ø¯ ÛŒØ¹Ù†ÛŒ:\n",
    "- Ù…Ø¯Ù„ Ø±ÙˆÛŒ 78.56Ùª Ø§Ø² Ú©Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø±Ø³Øª Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ú©Ø±Ø¯Ù‡\n",
    "\n",
    "Ø§Ù…Ø§ Ú†ÙˆÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù†Ø§Ø¨Ø±Ø§Ø¨Ø±Ù†Ø¯ (ÙÙ‚Ø· 49,715 Ù…Ø«Ø¨Øª Ø¯Ø§Ø±ÛŒÙ… Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± 160,000 Ù…Ù†ÙÛŒ)ØŒ Ø¯Ù‚Øª **Ø¯Ø± ÙˆØ§Ù‚Ø¹ Ú¯Ù…Ø±Ø§Ù‡â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ù‡Ø³Øª**.\n",
    "\n",
    "Ú†ÙˆÙ† Ù…Ø¯Ù„ Ø¨ÛŒØ´ØªØ± Ø¯Ø§Ø¯Ù‡ Ù…Ù†ÙÛŒ Ø¯ÛŒØ¯Ù‡ØŒ Ø¨ÛŒØ´ØªØ± Ø¬Ù…Ù„Ù‡â€ŒÙ‡Ø§ Ø±Ùˆ Ù…Ù†ÙÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÛŒÚ©Ù†Ù‡ â€“ Ø­ØªÛŒ Ø§Ú¯Ù‡ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù…Ø«Ø¨Øª Ø¨Ø§Ø´Ù†.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¤” Ú†Ø·ÙˆØ± Ø§ÛŒÙ† Ù…Ø´Ú©Ù„ Ø±Ùˆ Ø­Ù„ Ú©Ù†ÛŒÙ…ØŸ\n",
    "\n",
    "### âœ… Ø±Ø§Ù‡â€ŒØ­Ù„ Û±: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² `class_weight='balanced'` Ø¯Ø± Ù…Ø¯Ù„\n",
    "\n",
    "```python\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "```\n",
    "\n",
    "Ø§ÛŒÙ† Ú©Ø§Ø± Ø¨Ø§Ø¹Ø« Ù…ÛŒØ´Ù‡ Ù…Ø¯Ù„ **Ø¨Ù‡ Ú©Ù„Ø§Ø³ Ù…Ø«Ø¨Øª Ù‡Ù… ÙˆØ²Ù† Ø¨ÛŒØ´ØªØ±ÛŒ Ø¨Ø¯Ù‡**\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Ø±Ø§Ù‡â€ŒØ­Ù„ Û²: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² **resampling** (Ù…Ø«Ù„ SMOTE)\n",
    "\n",
    "Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø«Ø¨Øª Ù‚Ø¨Ù„ Ø§Ø² Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ â€“ ÙˆÙ„ÛŒ Ø§Ù„Ø§Ù† ÙØ¹Ù„Ø§Ù‹ Ø§ÛŒÙ†Ùˆ ÙØ±Ø§Ù…ÙˆØ´ Ú©Ù†\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Ø®Ù„Ø§ØµÙ‡ Ø³Ø§Ø¯Ù‡:\n",
    "\n",
    "| Ù…Ø¹ÛŒØ§Ø± | Ú†ÛŒ Ø±Ùˆ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù‡ØŸ | ÙˆÙ‚ØªÛŒ Ù…Ù‡Ù…Ù‡ØŸ |\n",
    "|-------|----------------------|-------------|\n",
    "| `accuracy` | Ú†Ù†Ø¯ Ø¯Ø±ØµØ¯ Ú©Ù„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ Ø¯Ø±Ø³Øª Ø¨ÙˆØ¯ØŸ | Ø¯Ø§Ø¯Ù‡ Ù…ØªÙˆØ§Ø²Ù† Ø¨Ø§Ø´Ù‡ |\n",
    "| `precision` | ÙˆÙ‚ØªÛŒ Ú¯ÙØª \"Ù…Ø«Ø¨Øª\"ØŒ Ú†Ù†Ø¯ Ø¯Ø±ØµØ¯ Ø¯Ø±Ø³Øª Ø¨ÙˆØ¯ØŸ | Ù†Ø®ÙˆØ§ÛŒÙ… Ø§Ø´ØªØ¨Ø§Ù‡ Ø¨Ú¯ÛŒÙ… \"Ù…Ø«Ø¨Øª\" (Ù…Ø«Ù„ ØªØ´Ø®ÛŒØµ Ø§ÛŒÙ…ÛŒÙ„ Ø§Ø³Ù¾Ù…) |\n",
    "| `recall` | Ø§Ø² Ø¨ÛŒÙ† ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù…Ø«Ø¨Øªâ€ŒÙ‡Ø§ØŒ Ú†Ù†Ø¯ Ø¯Ø±ØµØ¯ Ø±Ùˆ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯ÛŒÙ…ØŸ | Ù†Ø®ÙˆØ§ÛŒÙ… Ø¬Ù…Ù„Ù‡ Ù…Ø«Ø¨ØªÛŒ Ø±Ùˆ Ø§Ø² Ø¯Ø³Øª Ø¨Ø¯ÛŒÙ… (Ù…Ø«Ù„ ØªØ´Ø®ÛŒØµ Ø¨ÛŒÙ…Ø§Ø±ÛŒ) |\n",
    "| `f1-score` | ØªØ¹Ø§Ø¯Ù„ Ø¨ÛŒÙ† precision Ùˆ recall | Ù‡Ø± Ø¯Ùˆ Ù…Ø¹ÛŒØ§Ø± Ù…Ù‡Ù… Ø¨Ø§Ø´Ù† |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‘‡ Ù…Ø±Ø­Ù„Ù‡ Ø¨Ø¹Ø¯:\n",
    "\n",
    "Ø­Ø§Ù„Ø§ Ú©Ù‡ Ù…ØªÙˆØ¬Ù‡ Ø´Ø¯ÛŒ Ø§ÛŒÙ† Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ Ú†ÛŒâ€ŒÚ©Ø§Ø± Ù…ÛŒÚ©Ù†Ù†ØŒ Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒÙ…:\n",
    "\n",
    "1. Ù…Ø¯Ù„ Ø±Ùˆ Ø¨Ù‡ØªØ± Ú©Ù†ÛŒÙ… (Ø¨Ø§ `class_weight='balanced'`)\n",
    "2. Confusion Matrix Ø±Ùˆ Ø±Ø³Ù… Ú©Ù†ÛŒÙ…\n",
    "3. Cross Validation Ø§Ù†Ø¬Ø§Ù… Ø¨Ø¯ÛŒÙ…\n",
    "4. ÛŒØ§ Ø­ØªÛŒ ÛŒÙ‡ Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ Ø³Ø§Ø¯Ù‡ Ø¨Ù†Ø§ Ú©Ù†ÛŒÙ…\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¤” Ø³ÙˆØ§Ù„ Ø¢Ø®Ø±:\n",
    "\n",
    "- Ø§Ù„Ø§Ù† Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ Ø±Ùˆ ÙÙ‡Ù…ÛŒØ¯ÛŒØŸ\n",
    "- Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒÙ… Ú†Ù‡ Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ Ø±Ùˆ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÛŒÙ…ØŸ\n",
    "  - Ø§Ù„Ù) Ø¨Ù‡ØªØ± Ú©Ø±Ø¯Ù† Ù…Ø¯Ù„ (balance class)\n",
    "  - Ø¨) Ø±Ø³Ù… Confusion Matrix\n",
    "  - Ø¬) Cross Validation\n",
    "  - Ø¯) Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ\n",
    "\n",
    "Ù…Ù†ØªØ¸Ø± Ø¬ÙˆØ§Ø¨Øª Ù‡Ø³ØªÙ… ğŸ˜Š  \n",
    "ÙˆÙ‚ØªÛŒ Ú¯ÙØªÛŒ \"Ø§Ù„Ù\" ÛŒØ§ \"Ø¨\" ÛŒØ§ ...ØŒ Ù…Ù† Ú©Ø¯ Ùˆ ØªÙˆØ¶ÛŒØ­Ø´Ùˆ Ø¨Ø±Ø§Øª Ù…ÛŒâ€ŒÙØ±Ø³ØªÙ….\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586311c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7f49ee5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
